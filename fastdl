#!/usr/bin/env bash

# FastDL - High-Performance Cross-Platform Downloader
# Version: 0.0.1

set -euo pipefail

# Configuration and globals
FASTDL_VERSION="0.0.1"
FASTDL_DIR="$HOME/.fastdl"
FASTDL_CORE="$FASTDL_DIR/fastdl-core"
FASTDL_CONFIG="$FASTDL_DIR/config.json"
DOWNLOADS_DIR="$HOME/Downloads/FastDL"
TEMP_DIR="/tmp/fastdl-$$"

# Colors for beautiful output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_header() {
    echo -e "\n${PURPLE}${BOLD}=== $1 ===${NC}\n"
}

# Progress spinner for long operations
show_spinner() {
    local -r delay=0.1
    local spinstr="|/-\\"
    local temp
    while true; do
        temp="${spinstr#?}"
        printf " [%c]  " "${spinstr}"
        spinstr=${temp}${spinstr%"${temp}"}
        sleep "${delay}"
        printf "\b\b\b\b\b\b"
    done
}

# Clean up function
cleanup() {
    [[ -d "$TEMP_DIR" ]] && rm -rf "$TEMP_DIR"
    # Kill spinner if running
    jobs -p | xargs -r kill 2>/dev/null || true
}

trap cleanup EXIT

# Check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Detect system architecture and OS
detect_system() {
    local os
    local arch
    
    case "$(uname -s)" in
        Linux*)     os="linux" ;;
        Darwin*)    os="macos" ;;
        *)          log_error "Unsupported operating system: $(uname -s)"
                    exit 1 ;;
    esac
    
    case "$(uname -m)" in
        x86_64|amd64)   arch="x86_64" ;;
        aarch64|arm64)  arch="aarch64" ;;
        armv7l)         arch="armv7" ;;
        *)              log_error "Unsupported architecture: $(uname -m)"
                        exit 1 ;;
    esac
    
    echo "${os}-${arch}"
}

# Install Rust if not present
install_rust() {
    if command_exists rustc && command_exists cargo; then
        log_info "Rust is already installed"
        return 0
    fi
    
    log_info "Installing Rust toolchain..."
    
    # Download and install rustup
    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --default-toolchain stable
    
    # Source the cargo environment
    source "$HOME/.cargo/env" 2>/dev/null || true
    
    if command_exists rustc && command_exists cargo; then
        log_success "Rust installed successfully"
    else
        log_error "Failed to install Rust"
        exit 1
    fi
}

# Install system dependencies
install_dependencies() {
    log_info "Installing system dependencies..."
    
    case "$(uname -s)" in
        Linux*)
            # Detect package manager and install dependencies
            if command_exists apt-get; then
                sudo apt-get update >/dev/null 2>&1
                sudo apt-get install -y curl build-essential pkg-config libssl-dev >/dev/null 2>&1
            elif command_exists yum; then
                sudo yum groupinstall -y "Development Tools" >/dev/null 2>&1
                sudo yum install -y curl openssl-devel >/dev/null 2>&1
            elif command_exists dnf; then
                sudo dnf groupinstall -y "Development Tools" >/dev/null 2>&1
                sudo dnf install -y curl openssl-devel >/dev/null 2>&1
            elif command_exists pacman; then
                sudo pacman -Sy --noconfirm base-devel curl openssl >/dev/null 2>&1
            elif command_exists zypper; then
                sudo zypper install -y -t pattern devel_basis >/dev/null 2>&1
                sudo zypper install -y curl libopenssl-devel >/dev/null 2>&1
            else
                log_warning "Unknown package manager. Please install: curl, build-essential, pkg-config, libssl-dev"
            fi
            ;;
        Darwin*)
            # macOS - check if Xcode command line tools are installed
            if ! xcode-select -p >/dev/null 2>&1; then
                log_info "Installing Xcode command line tools..."
                xcode-select --install
                log_info "Please complete Xcode installation and run this script again"
                exit 1
            fi
            ;;
    esac
}

# Build the Rust core - FIXED VERSION
build_core() {
    log_info "Building FastDL core engine..."
    
    mkdir -p "$TEMP_DIR"
    cd "$TEMP_DIR"
    
    # Create the Rust project structure
    mkdir -p src
    
    # Fixed Cargo.toml with proper dependencies
    cat > Cargo.toml << 'EOF'
[package]
name = "fastdl-core"
version = "0.1.0"
edition = "2021"
authors = ["FastDL Team"]
description = "High-performance cross-platform file downloader core engine"
license = "MIT"

[[bin]]
name = "fastdl-core"
path = "src/main.rs"

[dependencies]
tokio = { version = "1.35", features = ["full"] }
futures-util = "0.3"
reqwest = { version = "0.11", features = ["stream", "json"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
url = "2.4"
urlencoding = "2.1"
indicatif = "0.17"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"
strip = true
EOF

    # Fixed Rust code with proper error handling and structure
    cat > src/main.rs << 'EOF'
use std::env;
use std::fs::File;
use std::io::{self, Write, Seek, SeekFrom};
use std::path::PathBuf;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use std::collections::HashMap;

use reqwest::Client;
use serde::{Deserialize, Serialize};
use tokio::fs::File as AsyncFile;
use tokio::io::{AsyncSeekExt, AsyncWriteExt};
use tokio::sync::{Semaphore, Mutex};
use tokio::time::sleep;
use futures_util::StreamExt;

// Configuration structure - received from wrapper scripts
#[derive(Debug, Deserialize)]
pub struct DownloadConfig {
    pub urls: Vec<String>,
    pub output_dir: String,
    pub connections: usize,
    pub chunk_size_mb: usize,
    pub timeout_seconds: u64,
    pub retries: usize,
    pub max_concurrent: usize,
    pub url_file: Option<String>,
    pub verbose: bool,
}

// Progress information sent back to wrapper
#[derive(Debug, Serialize)]
pub struct DownloadProgress {
    pub url: String,
    pub filename: String,
    pub total_size: u64,
    pub downloaded: u64,
    pub speed_mbps: f64,
    pub eta_seconds: u64,
    pub status: String,
}

// Final download result
#[derive(Debug, Serialize)]
pub struct DownloadResult {
    pub url: String,
    pub filename: String,
    pub success: bool,
    pub error: Option<String>,
    pub total_time_seconds: f64,
    pub average_speed_mbps: f64,
    pub file_size: u64,
}

// Chunk information for multi-threaded downloading
#[derive(Debug, Clone)]
pub struct ChunkInfo {
    pub start: u64,
    pub end: u64,
    pub size: u64,
    pub completed: bool,
    pub retries: usize,
}

// Statistics tracking for each download with thread-safe updates
pub struct DownloadStats {
    pub total_size: AtomicU64,
    pub downloaded: AtomicU64,
    pub start_time: Instant,
    pub chunks_completed: AtomicU64,
    pub chunks_total: AtomicU64,
}

impl DownloadStats {
    pub fn new() -> Self {
        Self {
            total_size: AtomicU64::new(0),
            downloaded: AtomicU64::new(0),
            start_time: Instant::now(),
            chunks_completed: AtomicU64::new(0),
            chunks_total: AtomicU64::new(0),
        }
    }

    // Calculate current download speed in MB/s
    pub fn speed_mbps(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed > 0.0 {
            let downloaded_mb = self.downloaded.load(Ordering::Relaxed) as f64 / (1024.0 * 1024.0);
            downloaded_mb / elapsed
        } else {
            0.0
        }
    }

    // Estimate time remaining in seconds
    pub fn eta_seconds(&self) -> u64 {
        let speed = self.speed_mbps();
        let remaining_mb = (self.total_size.load(Ordering::Relaxed) - self.downloaded.load(Ordering::Relaxed)) as f64 / (1024.0 * 1024.0);
        if speed > 0.0 {
            (remaining_mb / speed) as u64
        } else {
            0
        }
    }

    // Get completion percentage
    pub fn completion_percentage(&self) -> f64 {
        let total = self.total_size.load(Ordering::Relaxed);
        if total > 0 {
            (self.downloaded.load(Ordering::Relaxed) as f64 / total as f64) * 100.0
        } else {
            0.0
        }
    }
}

pub struct FastDownloader {
    client: Client,
    config: DownloadConfig,
    semaphore: Arc<Semaphore>, // Controls concurrent connections
}

impl FastDownloader {
    pub fn new(config: DownloadConfig) -> Result<Self, Box<dyn std::error::Error>> {
        // Create optimized HTTP client with connection pooling
        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout_seconds))
            .user_agent("FastDL-Core/1.0 (High-Performance Downloader)")
            .pool_max_idle_per_host(config.connections)
            .pool_idle_timeout(Duration::from_secs(30))
            .tcp_keepalive(Duration::from_secs(60))
            .build()?;

        // Create semaphore to limit concurrent connections
        let semaphore = Arc::new(Semaphore::new(config.connections));

        Ok(Self { client, config, semaphore })
    }

    // Extract filename from URL with better handling
    fn extract_filename(&self, url: &str) -> String {
        if let Ok(parsed_url) = url::Url::parse(url) {
            if let Some(segments) = parsed_url.path_segments() {
                if let Some(last_segment) = segments.last() {
                    if !last_segment.is_empty() {
                        let decoded = urlencoding::decode(last_segment).unwrap_or_default();
                        let filename = decoded.to_string();
                        // Remove query parameters if present
                        if let Some(clean_name) = filename.split('?').next() {
                            if !clean_name.is_empty() {
                                return clean_name.to_string();
                            }
                        }
                    }
                }
            }
        }

        // Generate a meaningful name based on URL and timestamp
        let url_hash = url.chars().fold(0u32, |acc, c| acc.wrapping_add(c as u32));
        format!("download_{}_{}", url_hash, std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs())
    }

    // Check if server supports range requests
    async fn check_range_support(&self, url: &str) -> Result<bool, Box<dyn std::error::Error>> {
        let response = self.client.head(url).send().await?;
        
        if !response.status().is_success() {
            return Err(format!("HTTP error: {}", response.status()).into());
        }

        // Check for Accept-Ranges header
        Ok(response.headers()
            .get("accept-ranges")
            .and_then(|v| v.to_str().ok())
            .map(|v| v.to_lowercase())
            .as_deref() == Some("bytes"))
    }

    // Get file information with enhanced error handling
    async fn get_file_info(&self, url: &str) -> Result<(u64, String, bool), Box<dyn std::error::Error>> {
        let mut retries = 0;
        let max_retries = 3;

        loop {
            match self.client.head(url).send().await {
                Ok(response) => {
                    if !response.status().is_success() {
                        return Err(format!("HTTP error: {}", response.status()).into());
                    }

                    // Get file size
                    let file_size = response
                        .headers()
                        .get("content-length")
                        .and_then(|v| v.to_str().ok())
                        .and_then(|v| v.parse::<u64>().ok())
                        .unwrap_or(0);

                    // Extract filename
                    let filename = self.extract_filename(url);

                    // Check range support
                    let supports_ranges = response.headers()
                        .get("accept-ranges")
                        .and_then(|v| v.to_str().ok())
                        .map(|v| v.to_lowercase())
                        .as_deref() == Some("bytes");

                    return Ok((file_size, filename, supports_ranges));
                }
                Err(e) => {
                    retries += 1;
                    if retries >= max_retries {
                        return Err(format!("Failed to get file info after {} retries: {}", max_retries, e).into());
                    }
                    
                    if self.config.verbose {
                        println!("Retry {}/{} for file info: {}", retries, max_retries, e);
                    }
                    
                    // Exponential backoff
                    sleep(Duration::from_millis(1000 * (1 << retries))).await;
                }
            }
        }
    }

    // Create chunks for multi-threaded downloading
    fn create_chunks(&self, file_size: u64, supports_ranges: bool) -> Vec<ChunkInfo> {
        if !supports_ranges || file_size == 0 {
            // Single chunk for servers that don't support ranges
            return vec![ChunkInfo {
                start: 0,
                end: file_size.saturating_sub(1),
                size: file_size,
                completed: false,
                retries: 0,
            }];
        }

        let chunk_size = (self.config.chunk_size_mb * 1024 * 1024) as u64;
        let num_chunks = std::cmp::min(
            self.config.connections as u64,
            (file_size + chunk_size - 1) / chunk_size
        );

        let mut chunks = Vec::new();
        let chunk_size_actual = file_size / num_chunks;
        let remainder = file_size % num_chunks;

        for i in 0..num_chunks {
            let start = i * chunk_size_actual;
            let mut end = start + chunk_size_actual - 1;
            
            // Add remainder to the last chunk
            if i == num_chunks - 1 {
                end += remainder;
            }

            chunks.push(ChunkInfo {
                start,
                end,
                size: end - start + 1,
                completed: false,
                retries: 0,
            });
        }

        chunks
    }

    // Download a single chunk with retry logic
    async fn download_chunk(
        &self,
        url: &str,
        chunk: ChunkInfo,
        file_path: &PathBuf,
        stats: Arc<DownloadStats>,
    ) -> Result<ChunkInfo, Box<dyn std::error::Error>> {
        let mut current_chunk = chunk;
        
        // Retry loop for this chunk
        while current_chunk.retries < self.config.retries {
            // Acquire semaphore permit to limit concurrent connections
            let _permit = self.semaphore.acquire().await?;
            
            match self.download_chunk_attempt(url, &current_chunk, file_path, stats.clone()).await {
                Ok(_) => {
                    current_chunk.completed = true;
                    stats.chunks_completed.fetch_add(1, Ordering::Relaxed);
                    return Ok(current_chunk);
                }
                Err(e) => {
                    current_chunk.retries += 1;
                    if self.config.verbose {
                        println!("Chunk {}-{} failed (attempt {}): {}", 
                            current_chunk.start, current_chunk.end, current_chunk.retries, e);
                    }
                    
                    if current_chunk.retries < self.config.retries {
                        // Exponential backoff with jitter
                        let delay = Duration::from_millis(500 * (1 << current_chunk.retries) + 
                            (fastrand::u64(0..1000)));
                        sleep(delay).await;
                    }
                }
            }
        }

        Err(format!("Chunk {}-{} failed after {} retries", 
            current_chunk.start, current_chunk.end, self.config.retries).into())
    }

    // Single attempt to download a chunk
    async fn download_chunk_attempt(
        &self,
        url: &str,
        chunk: &ChunkInfo,
        file_path: &PathBuf,
        stats: Arc<DownloadStats>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        // Create range request
        let mut request = self.client.get(url);
        
        if chunk.start > 0 || chunk.end < chunk.start + chunk.size {
            request = request.header("Range", format!("bytes={}-{}", chunk.start, chunk.end));
        }

        // Send request with per-chunk timeout
        let response = tokio::time::timeout(
            Duration::from_secs(self.config.timeout_seconds),
            request.send()
        ).await??;

        if !response.status().is_success() && response.status().as_u16() != 206 {
            return Err(format!("HTTP error: {}", response.status()).into());
        }

        // Open file for writing at the specific position
        let mut file = std::fs::OpenOptions::new()
            .create(true)
            .write(true)
            .open(file_path)?;
        
        file.seek(SeekFrom::Start(chunk.start))?;

        // Stream the chunk data
        let mut stream = response.bytes_stream();
        let mut chunk_downloaded = 0u64;

        while let Some(chunk_result) = stream.next().await {
            let data = chunk_result?;
            file.write_all(&data)?;
            
            let bytes_written = data.len() as u64;
            chunk_downloaded += bytes_written;
            stats.downloaded.fetch_add(bytes_written, Ordering::Relaxed);

            // Progress reporting for verbose mode
            if self.config.verbose && chunk_downloaded % (256 * 1024) == 0 {
                let progress = stats.completion_percentage();
                let speed = stats.speed_mbps();
                let eta = stats.eta_seconds();
                print!("\rProgress: {:.1}% | Speed: {:.2} MB/s | ETA: {}s", 
                    progress, speed, eta);
                io::stdout().flush().ok();
            }
        }

        file.flush()?;
        Ok(())
    }

    // Multi-threaded download with proper chunk management
    async fn download_multithread(
        &self,
        url: &str,
        file_path: &PathBuf,
        file_size: u64,
        supports_ranges: bool,
        stats: Arc<DownloadStats>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        // Create chunks for parallel downloading
        let chunks = self.create_chunks(file_size, supports_ranges);
        stats.chunks_total.store(chunks.len() as u64, Ordering::Relaxed);

        if self.config.verbose {
            println!("Using {} chunks for parallel download", chunks.len());
        }

        // Create the output file
        if file_size > 0 {
            let file = std::fs::File::create(file_path)?;
            file.set_len(file_size)?;
        }

        // Download chunks concurrently
        let mut handles = Vec::new();
        
        for chunk in chunks {
            let url = url.to_string();
            let file_path = file_path.clone();
            let stats = stats.clone();
            let downloader = self.clone();

            let handle = tokio::spawn(async move {
                downloader.download_chunk(&url, chunk, &file_path, stats).await
            });
            
            handles.push(handle);
        }

        // Wait for all chunks to complete
        let mut all_success = true;
        let mut error_messages = Vec::new();

        for handle in handles {
            match handle.await {
                Ok(Ok(_)) => {
                    // Chunk completed successfully
                }
                Ok(Err(e)) => {
                    all_success = false;
                    error_messages.push(e.to_string());
                }
                Err(e) => {
                    all_success = false;
                    error_messages.push(format!("Task error: {}", e));
                }
            }
        }

        if !all_success {
            return Err(format!("Some chunks failed: {}", error_messages.join("; ")).into());
        }

        Ok(())
    }

    // Fallback single-stream download for servers without range support
    async fn download_single_stream(
        &self,
        url: &str,
        file_path: &PathBuf,
        stats: Arc<DownloadStats>,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let response = self.client.get(url).send().await?;
        
        if !response.status().is_success() {
            return Err(format!("HTTP error: {}", response.status()).into());
        }

        let mut file = std::fs::File::create(file_path)?;
        let mut stream = response.bytes_stream();

        while let Some(chunk_result) = stream.next().await {
            let chunk = chunk_result?;
            file.write_all(&chunk)?;
            stats.downloaded.fetch_add(chunk.len() as u64, Ordering::Relaxed);

            // Progress reporting
            if self.config.verbose {
                let downloaded = stats.downloaded.load(Ordering::Relaxed);
                let total = stats.total_size.load(Ordering::Relaxed);
                if total > 0 {
                    let percent = (downloaded as f64 / total as f64) * 100.0;
                    let speed = stats.speed_mbps();
                    print!("\rProgress: {:.1}% | Speed: {:.2} MB/s", percent, speed);
                    io::stdout().flush().ok();
                }
            }
        }

        file.flush()?;
        if self.config.verbose {
            println!(); // New line after progress
        }
        Ok(())
    }

    // Main download function for a single file
    pub async fn download_file(&self, url: &str) -> DownloadResult {
        let start_time = Instant::now();
        
        if self.config.verbose {
            println!("Analyzing: {}", url);
        }

        // Get file information
        let (file_size, filename, supports_ranges) = match self.get_file_info(url).await {
            Ok(info) => info,
            Err(e) => {
                return DownloadResult {
                    url: url.to_string(),
                    filename: "unknown".to_string(),
                    success: false,
                    error: Some(format!("Failed to get file info: {}", e)),
                    total_time_seconds: start_time.elapsed().as_secs_f64(),
                    average_speed_mbps: 0.0,
                    file_size: 0,
                };
            }
        };

        let output_path = PathBuf::from(&self.config.output_dir).join(&filename);
        
        // Create output directory if needed
        if let Some(parent) = output_path.parent() {
            if let Err(e) = std::fs::create_dir_all(parent) {
                return DownloadResult {
                    url: url.to_string(),
                    filename,
                    success: false,
                    error: Some(format!("Failed to create output directory: {}", e)),
                    total_time_seconds: start_time.elapsed().as_secs_f64(),
                    average_speed_mbps: 0.0,
                    file_size,
                };
            }
        }

        let stats = Arc::new(DownloadStats::new());
        stats.total_size.store(file_size, Ordering::Relaxed);

        if self.config.verbose {
            println!("Downloading: {} -> {}", filename, output_path.display());
            if file_size > 0 {
                println!("File size: {} bytes", file_size);
            }
            println!("Range support: {}", if supports_ranges { "Yes" } else { "No" });
        }

        // Choose download strategy based on range support and file size
        let result = if supports_ranges && file_size > 1024 * 1024 && self.config.connections > 1 {
            // Multi-threaded download for large files with range support
            self.download_multithread(url, &output_path, file_size, supports_ranges, stats.clone()).await
        } else {
            // Single-stream download for small files or servers without range support
            self.download_single_stream(url, &output_path, stats.clone()).await
        };

        let total_time = start_time.elapsed().as_secs_f64();
        let downloaded = stats.downloaded.load(Ordering::Relaxed);
        let avg_speed = if total_time > 0.0 {
            (downloaded as f64 / (1024.0 * 1024.0)) / total_time
        } else {
            0.0
        };

        match result {
            Ok(_) => {
                if self.config.verbose {
                    println!("✓ Download completed: {}", filename);
                    println!("  Time: {:.2}s | Speed: {:.2} MB/s", total_time, avg_speed);
                }
                DownloadResult {
                    url: url.to_string(),
                    filename,
                    success: true,
                    error: None,
                    total_time_seconds: total_time,
                    average_speed_mbps: avg_speed,
                    file_size: downloaded,
                }
            }
            Err(e) => {
                if self.config.verbose {
                    println!("✗ Download failed: {}", e);
                }
                // Clean up partial file
                let _ = std::fs::remove_file(&output_path);
                DownloadResult {
                    url: url.to_string(),
                    filename,
                    success: false,
                    error: Some(e.to_string()),
                    total_time_seconds: total_time,
                    average_speed_mbps: avg_speed,
                    file_size: downloaded,
                }
            }
        }
    }

    // Download multiple files with controlled concurrency
    pub async fn download_batch(&self, urls: Vec<String>) -> Vec<DownloadResult> {
        let semaphore = Arc::new(Semaphore::new(self.config.max_concurrent));
        let mut handles = Vec::new();
        
        for url in urls {
            let semaphore = semaphore.clone();
            let downloader = self.clone();
            
            let handle = tokio::spawn(async move {
                let _permit = semaphore.acquire().await.unwrap();
                downloader.download_file(&url).await
            });
            
            handles.push(handle);
        }

        let mut results = Vec::new();
        for handle in handles {
            match handle.await {
                Ok(result) => results.push(result),
                Err(e) => {
                    results.push(DownloadResult {
                        url: "unknown".to_string(),
                        filename: "unknown".to_string(),
                        success: false,
                        error: Some(format!("Task error: {}", e)),
                        total_time_seconds: 0.0,
                        average_speed_mbps: 0.0,
                        file_size: 0,
                    });
                }
            }
        }

        results
    }
}

// Implement Clone for FastDownloader to enable sharing across tasks
impl Clone for FastDownloader {
    fn clone(&self) -> Self {
        Self {
            client: self.client.clone(),
            config: DownloadConfig {
                urls: self.config.urls.clone(),
                output_dir: self.config.output_dir.clone(),
                connections: self.config.connections,
                chunk_size_mb: self.config.chunk_size_mb,
                timeout_seconds: self.config.timeout_seconds,
                retries: self.config.retries,
                max_concurrent: self.config.max_concurrent,
                url_file: self.config.url_file.clone(),
                verbose: self.config.verbose,
            },
            semaphore: self.semaphore.clone(),
        }
    }
}

// Add fastrand dependency for jitter in retry delays
mod fastrand {
    use std::collections::hash_map::DefaultHasher;
    use std::hash::{Hash, Hasher};
    use std::sync::atomic::{AtomicU64, Ordering};
    
    static SEED: AtomicU64 = AtomicU64::new(1);
    
    pub fn u64(range: std::ops::Range<u64>) -> u64 {
        let mut hasher = DefaultHasher::new();
        std::thread::current().id().hash(&mut hasher);
        std::time::SystemTime::now().duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default().as_nanos().hash(&mut hasher);
        SEED.fetch_add(1, Ordering::Relaxed).hash(&mut hasher);
        
        let hash = hasher.finish();
        range.start + (hash % (range.end - range.start))
    }
}

// Main entry point
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let args: Vec<String> = env::args().collect();
    
    if args.len() < 2 {
        eprintln!("Usage: fastdl-core <config-json>");
        eprintln!("Example: fastdl-core '{{\"urls\":[\"https://example.com/file.zip\"],\"output_dir\":\"./downloads\",\"connections\":8,\"chunk_size_mb\":1,\"timeout_seconds\":30,\"retries\":3,\"max_concurrent\":3,\"verbose\":true}}'");
        std::process::exit(1);
    }

    // Parse configuration from JSON argument
    let config: DownloadConfig = serde_json::from_str(&args[1])
        .map_err(|e| format!("Invalid JSON config: {}", e))?;

    let downloader = FastDownloader::new(config)?;

    // Determine what to download
    let urls = if let Some(url_file) = &downloader.config.url_file {
        // Read URLs from file
        let content = std::fs::read_to_string(url_file)?;
        content.lines()
            .map(|line| line.trim().to_string())
            .filter(|line| !line.is_empty() && !line.starts_with('#'))
            .collect()
    } else {
        downloader.config.urls.clone()
    };

    if urls.is_empty() {
        eprintln!("No URLs to download");
        std::process::exit(1);
    }

    // Execute downloads
    let results = if urls.len() == 1 {
        vec![downloader.download_file(&urls[0]).await]
    } else {
        downloader.download_batch(urls).await
    };

    // Output final results as JSON
    println!("{}", serde_json::to_string_pretty(&results)?);

    // Exit with appropriate code
    let success_count = results.iter().filter(|r| r.success).count();
    if success_count == results.len() {
        std::process::exit(0);
    } else {
        std::process::exit(1);
    }
}
EOF
    
    # Build in release mode for maximum performance
    show_spinner &
    local spinner_pid=$!
    
    # Source cargo environment to ensure it's available
    source "$HOME/.cargo/env" 2>/dev/null || true
    
    # Build with better error reporting
    if RUST_BACKTRACE=1 cargo build --release 2>"$TEMP_DIR/build.log"; then
        kill $spinner_pid 2>/dev/null || true
        wait $spinner_pid 2>/dev/null || true
        log_success "Core engine built successfully"
    else
        kill $spinner_pid 2>/dev/null || true
        wait $spinner_pid 2>/dev/null || true
        log_error "Failed to build core engine"
        log_info "Build log:"
        cat "$TEMP_DIR/build.log"
        exit 1
    fi
    
    # Copy the binary to FastDL directory
    mkdir -p "$FASTDL_DIR"
    cp target/release/fastdl-core "$FASTDL_CORE"
    chmod +x "$FASTDL_CORE"
}

# Initialize FastDL configuration
init_config() {
    log_info "Initializing FastDL configuration..."
    
    mkdir -p "$FASTDL_DIR"
    mkdir -p "$DOWNLOADS_DIR"
    
    # Create default configuration
    cat > "$FASTDL_CONFIG" << EOF
{
    "default_connections": 8,
    "default_chunk_size_mb": 1,
    "default_timeout_seconds": 30,
    "default_retries": 3,
    "default_max_concurrent": 3,
    "downloads_directory": "$DOWNLOADS_DIR",
    "verbose": false,
    "auto_organize": true,
    "resume_downloads": true
}
EOF
    
    log_success "Configuration initialized"
}

# Setup function - called on first run or when --setup is used
setup_fastdl() {
    log_header "FastDL Setup"
    
    log_info "Setting up FastDL v$FASTDL_VERSION for $(detect_system)"
    
    # Install dependencies
    install_dependencies
    
    # Install Rust
    install_rust
    
    # Build core
    build_core
    
    # Initialize config
    init_config
    
    # Create desktop entry on Linux
    if [[ "$(uname -s)" == "Linux" ]] && [[ -d "$HOME/.local/share/applications" ]]; then
        cat > "$HOME/.local/share/applications/fastdl.desktop" << EOF
[Desktop Entry]
Version=1.0
Type=Application
Name=FastDL
Comment=High-Performance File Downloader
Exec=$0
Icon=folder-download
Terminal=true
Categories=Network;FileTransfer;
EOF
    fi
    
    log_success "FastDL setup completed successfully!"
    echo
    log_info "You can now run 'fastdl' from anywhere"
    log_info "Downloads will be saved to: $DOWNLOADS_DIR"
}

# Check if FastDL is properly installed
check_installation() {
    if [[ ! -f "$FASTDL_CORE" ]] || [[ ! -f "$FASTDL_CONFIG" ]]; then
        return 1
    fi
    return 0
}

# Load configuration
load_config() {
    if [[ -f "$FASTDL_CONFIG" ]]; then
        # Parse JSON config (simple extraction for bash)
        DEFAULT_CONNECTIONS=$(grep -o '"default_connections":[[:space:]]*[0-9]*' "$FASTDL_CONFIG" | grep -o '[0-9]*$' || echo "8")
        DEFAULT_CHUNK_SIZE=$(grep -o '"default_chunk_size_mb":[[:space:]]*[0-9]*' "$FASTDL_CONFIG" | grep -o '[0-9]*$' || echo "1")
        DEFAULT_TIMEOUT=$(grep -o '"default_timeout_seconds":[[:space:]]*[0-9]*' "$FASTDL_CONFIG" | grep -o '[0-9]*$' || echo "30")
        DEFAULT_RETRIES=$(grep -o '"default_retries":[[:space:]]*[0-9]*' "$FASTDL_CONFIG" | grep -o '[0-9]*$' || echo "3")
        DEFAULT_MAX_CONCURRENT=$(grep -o '"default_max_concurrent":[[:space:]]*[0-9]*' "$FASTDL_CONFIG" | grep -o '[0-9]*$' || echo "3")
        DOWNLOADS_DIR=$(grep -o '"downloads_directory":[[:space:]]*"[^"]*"' "$FASTDL_CONFIG" | sed 's/.*"\([^"]*\)".*/\1/' || echo "$HOME/Downloads/FastDL")
    else
        # Fallback defaults
        DEFAULT_CONNECTIONS=8
        DEFAULT_CHUNK_SIZE=1
        DEFAULT_TIMEOUT=30
        DEFAULT_RETRIES=3
        DEFAULT_MAX_CONCURRENT=3
        DOWNLOADS_DIR="$HOME/Downloads/FastDL"
    fi
}

# Validate URL
is_valid_url() {
    local url="$1"
    if [[ "$url" =~ ^https?:// ]]; then
        return 0
    fi
    return 1
}

# Format file size
format_size() {
    local size=$1
    if [[ $size -gt 1073741824 ]]; then
        echo "$(( size / 1073741824 )) GB"
    elif [[ $size -gt 1048576 ]]; then
        echo "$(( size / 1048576 )) MB"
    elif [[ $size -gt 1024 ]]; then
        echo "$(( size / 1024 )) KB"
    else
        echo "$size B"
    fi
}

# Download single file
download_single() {
    local url="$1"
    local output_dir="${2:-$DOWNLOADS_DIR}"
    local connections="${3:-$DEFAULT_CONNECTIONS}"
    local chunk_size="${4:-$DEFAULT_CHUNK_SIZE}"
    local timeout="${5:-$DEFAULT_TIMEOUT}"
    local retries="${6:-$DEFAULT_RETRIES}"
    local verbose="${7:-false}"
    
    log_info "Starting download..."
    log_info "URL: $url"
    log_info "Output: $output_dir"
    log_info "Connections: $connections"
    
    # Create JSON configuration for the core
    local config=$(cat << EOF
{
    "urls": ["$url"],
    "output_dir": "$output_dir",
    "connections": $connections,
    "chunk_size_mb": $chunk_size,
    "timeout_seconds": $timeout,
    "retries": $retries,
    "max_concurrent": 1,
    "verbose": $verbose
}
EOF
)
    
    # Execute the core downloader
    mkdir -p "$output_dir"
    
    if "$FASTDL_CORE" "$config"; then
        log_success "Download completed successfully!"
        log_info "File saved to: $output_dir"
    else
        log_error "Download failed"
        return 1
    fi
}

# Download from file list
download_batch() {
    local url_file="$1"
    local output_dir="${2:-$DOWNLOADS_DIR}"
    local connections="${3:-$DEFAULT_CONNECTIONS}"
    local max_concurrent="${4:-$DEFAULT_MAX_CONCURRENT}"
    local verbose="${5:-false}"
    
    if [[ ! -f "$url_file" ]]; then
        log_error "URL file not found: $url_file"
        return 1
    fi
    
    local url_count=$(grep -c -v '^[[:space:]]*$\|^#' "$url_file" || echo "0")
    
    log_info "Starting batch download..."
    log_info "URLs: $url_count"
    log_info "Output: $output_dir"
    log_info "Connections per file: $connections"
    log_info "Concurrent downloads: $max_concurrent"
    
    # Create JSON configuration for the core
    local config=$(cat << EOF
{
    "urls": [],
    "output_dir": "$output_dir",
    "connections": $connections,
    "chunk_size_mb": $DEFAULT_CHUNK_SIZE,
    "timeout_seconds": $DEFAULT_TIMEOUT,
    "retries": $DEFAULT_RETRIES,
    "max_concurrent": $max_concurrent,
    "url_file": "$url_file",
    "verbose": $verbose
}
EOF
)
    
    # Execute the core downloader
    mkdir -p "$output_dir"
    
    if "$FASTDL_CORE" "$config"; then
        log_success "Batch download completed!"
        log_info "Files saved to: $output_dir"
    else
        log_error "Batch download failed"
        return 1
    fi
}

# Interactive menu system
show_main_menu() {
    clear
    echo -e "${CYAN}${BOLD}"
    echo "  ╔═══════════════════════════════════════╗"
    echo "  ║        FastDL v$FASTDL_VERSION        ║"
    echo "  ║    High-Performance File Downloader   ║"
    echo "  ║  Engineered by 0xb0rn3 | Ig: theehiv3 ║"
    echo "  ╚═══════════════════════════════════════╝"
    echo -e "${NC}"
    echo
    echo -e "${BOLD}Select an option:${NC}"
    echo
    echo "  1) Download Single File"
    echo "  2) Download Multiple Files (from list)"
    echo "  3) Configuration"
    echo "  4) Download History"
    echo "  5) Help & About"
    echo "  6) Exit"
    echo
    echo -n "Enter your choice [1-6]: "
}

# Single file download menu
single_download_menu() {
    clear
    log_header "Single File Download"
    
    echo -n "Enter URL: "
    read -r url
    
    if ! is_valid_url "$url"; then
        log_error "Invalid URL format"
        echo "Press Enter to continue..."
        read -r
        return
    fi
    
    echo
    echo "Advanced options (press Enter for defaults):"
    echo -n "Output directory [$DOWNLOADS_DIR]: "
    read -r output_dir
    output_dir="${output_dir:-$DOWNLOADS_DIR}"
    
    echo -n "Number of connections [$DEFAULT_CONNECTIONS]: "
    read -r connections
    connections="${connections:-$DEFAULT_CONNECTIONS}"
    
    echo -n "Verbose output? [y/N]: "
    read -r verbose_input
    local verbose="false"
    if [[ "$verbose_input" =~ ^[Yy] ]]; then
        verbose="true"
    fi
    
    echo
    download_single "$url" "$output_dir" "$connections" "$DEFAULT_CHUNK_SIZE" "$DEFAULT_TIMEOUT" "$DEFAULT_RETRIES" "$verbose"
    
    echo
    echo "Press Enter to continue..."
    read -r
}

# Batch download menu
batch_download_menu() {
    clear
    log_header "Batch Download"
    
    echo "You can provide a file containing URLs (one per line)"
    echo "Lines starting with # are treated as comments"
    echo
    echo -n "Enter path to URL file: "
    read -r url_file
    
    if [[ ! -f "$url_file" ]]; then
        log_error "File not found: $url_file"
        echo "Press Enter to continue..."
        read -r
        return
    fi
    
    echo
    echo "Advanced options (press Enter for defaults):"
    echo -n "Output directory [$DOWNLOADS_DIR]: "
    read -r output_dir
    output_dir="${output_dir:-$DOWNLOADS_DIR}"
    
    echo -n "Connections per file [$DEFAULT_CONNECTIONS]: "
    read -r connections
    connections="${connections:-$DEFAULT_CONNECTIONS}"
    
    echo -n "Max concurrent downloads [$DEFAULT_MAX_CONCURRENT]: "
    read -r max_concurrent
    max_concurrent="${max_concurrent:-$DEFAULT_MAX_CONCURRENT}"
    
    echo -n "Verbose output? [y/N]: "
    read -r verbose_input
    local verbose="false"
    if [[ "$verbose_input" =~ ^[Yy] ]]; then
        verbose="true"
    fi
    
    echo
    download_batch "$url_file" "$output_dir" "$connections" "$max_concurrent" "$verbose"
    
    echo
    echo "Press Enter to continue..."
    read -r
}

# Configuration menu
config_menu() {
    clear
    log_header "Configuration"
    
    load_config
    
    echo "Current configuration:"
    echo "  Default connections: $DEFAULT_CONNECTIONS"
    echo "  Default chunk size: ${DEFAULT_CHUNK_SIZE}MB"
    echo "  Default timeout: ${DEFAULT_TIMEOUT}s"
    echo "  Default retries: $DEFAULT_RETRIES"
    echo "  Max concurrent: $DEFAULT_MAX_CONCURRENT"
    echo "  Downloads directory: $DOWNLOADS_DIR"
    echo
    echo "1) Change defaults"
    echo "2) Open downloads directory"
    echo "3) Reset to defaults"
    echo "4) Back to main menu"
    echo
    echo -n "Enter your choice [1-4]: "
    read -r choice
    
    case "$choice" in
        1)
            echo
            echo "Enter new values (press Enter to keep current):"
            
            echo -n "Default connections [$DEFAULT_CONNECTIONS]: "
            read -r new_connections
            connections="${new_connections:-$DEFAULT_CONNECTIONS}"
            
            echo -n "Default chunk size MB [$DEFAULT_CHUNK_SIZE]: "
            read -r new_chunk_size
            chunk_size="${new_chunk_size:-$DEFAULT_CHUNK_SIZE}"
            
            echo -n "Default timeout seconds [$DEFAULT_TIMEOUT]: "
            read -r new_timeout
            timeout="${new_timeout:-$DEFAULT_TIMEOUT}"
            
            echo -n "Default retries [$DEFAULT_RETRIES]: "
            read -r new_retries
            retries="${new_retries:-$DEFAULT_RETRIES}"
            
            echo -n "Max concurrent downloads [$DEFAULT_MAX_CONCURRENT]: "
            read -r new_max_concurrent
            max_concurrent="${new_max_concurrent:-$DEFAULT_MAX_CONCURRENT}"
            
            # Update configuration file
            cat > "$FASTDL_CONFIG" << EOF
{
    "default_connections": $connections,
    "default_chunk_size_mb": $chunk_size,
    "default_timeout_seconds": $timeout,
    "default_retries": $retries,
    "default_max_concurrent": $max_concurrent,
    "downloads_directory": "$DOWNLOADS_DIR",
    "verbose": false,
    "auto_organize": true,
    "resume_downloads": true
}
EOF
            log_success "Configuration updated!"
            ;;
        2)
            if command_exists xdg-open; then
                xdg-open "$DOWNLOADS_DIR" >/dev/null 2>&1 &
            elif command_exists open; then
                open "$DOWNLOADS_DIR" >/dev/null 2>&1 &
            else
                log_info "Downloads directory: $DOWNLOADS_DIR"
            fi
            ;;
        3)
            init_config
            log_success "Configuration reset to defaults!"
            ;;
        4)
            return
            ;;
    esac
    
    echo
    echo "Press Enter to continue..."
    read -r
}

# Help menu
help_menu() {
    clear
    log_header "Help & About"
    
    echo -e "${BOLD}FastDL v$FASTDL_VERSION${NC}"
    echo "High-Performance Cross-Platform File Downloader"
    echo
    echo -e "${BOLD}Features:${NC}"
    echo "  • Multi-connection downloads for maximum speed"
    echo "  • Concurrent downloading of multiple files"
    echo "  • Automatic resume of interrupted downloads"
    echo "  • Smart chunk-based downloading"
    echo "  • Cross-platform support (Linux, macOS, Windows)"
    echo "  • Built with Rust for maximum performance"
    echo
    echo -e "${BOLD}Command Line Usage:${NC}"
    echo "  fastdl                    - Interactive menu (current mode)"
    echo "  fastdl <url>              - Download single file"
    echo "  fastdl --file <file>      - Download from URL list"
    echo "  fastdl --setup            - Run setup again"
    echo "  fastdl --help             - Show help"
    echo
    echo -e "${BOLD}Configuration:${NC}"
    echo "  Config file: $FASTDL_CONFIG"
    echo "  Downloads:   $DOWNLOADS_DIR"
    echo "  Core binary: $FASTDL_CORE"
    echo
    echo -e "${BOLD}URL List Format:${NC}"
    echo "  One URL per line"
    echo "  Lines starting with # are comments"
    echo "  Empty lines are ignored"
    echo
    echo "Press Enter to continue..."
    read -r
}

# Command line argument handling
handle_args() {
    case "${1:-}" in
        --setup)
            setup_fastdl
            exit 0
            ;;
        --help|-h)
            help_menu
            exit 0
            ;;
        --file|-f)
            if [[ -z "${2:-}" ]]; then
                log_error "Please specify a file path"
                exit 1
            fi
            load_config
            download_batch "$2"
            exit $?
            ;;
        http://*|https://*)
            load_config
            download_single "$1"
            exit $?
            ;;
        "")
            # No arguments - run interactive mode
            ;;
        *)
            echo "FastDL v$FASTDL_VERSION - High-Performance File Downloader"
            echo
            echo "Usage:"
            echo "  $0                    - Interactive menu"
            echo "  $0 <url>              - Download single file"
            echo "  $0 --file <file>      - Download from URL list"
            echo "  $0 --setup            - Run setup"
            echo "  $0 --help             - Show help"
            exit 1
            ;;
    esac
}

# Main interactive loop
interactive_mode() {
    while true; do
        show_main_menu
        read -r choice
        
        case "$choice" in
            1)
                single_download_menu
                ;;
            2)
                batch_download_menu
                ;;
            3)
                config_menu
                ;;
            4)
                # Download history - placeholder for future implementation
                clear
                log_header "Download History"
                echo "Feature coming soon!"
                echo
                echo "Press Enter to continue..."
                read -r
                ;;
            5)
                help_menu
                ;;
            6)
                echo
                log_info "Thanks for using FastDL!"
                exit 0
                ;;
            *)
                echo
                log_error "Invalid choice. Please enter 1-6."
                sleep 1
                ;;
        esac
    done
}

# Main execution
main() {
    # Handle command line arguments first
    handle_args "$@"
    
    # Check if FastDL is installed
    if ! check_installation; then
        log_header "FastDL First-Time Setup Required"
        echo "FastDL needs to be set up before first use."
        echo "This will:"
        echo "  • Install Rust toolchain (if needed)"
        echo "  • Install system dependencies"
        echo "  • Build the high-performance core engine"
        echo "  • Create configuration files"
        echo
        echo -n "Proceed with setup? [Y/n]: "
        read -r setup_choice
        
        if [[ ! "$setup_choice" =~ ^[Nn] ]]; then
            setup_fastdl
        else
            log_error "Setup cancelled. FastDL cannot run without setup."
            exit 1
        fi
    fi
    
    # Load configuration
    load_config
    
    # Start interactive mode
    interactive_mode
}

# Execute main function with all arguments
main "$@"
