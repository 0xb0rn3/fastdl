#!/usr/bin/env bash

# FastDL - Pure Bash Implementation
# Extremely fast concurrent downloader for massive files
# Linux-native with zero external dependencies beyond standard tools

set -euo pipefail

# Version and metadata
readonly SCRIPT_VERSION="1.0.0"
readonly SCRIPT_NAME="FastDL"
readonly SCRIPT_AUTHOR="0xb0rn3 | 0xbv1"
readonly SCRIPT_CONTACT="Discord: oxbv1 | X: oxbv1 | Instagram: theehiv3 | Email: q4n0@proton.me"
readonly SCRIPT_REPO="https://github.com/0xb0rn3/fastdl"

# Global configuration
readonly CONFIG_DIR="$HOME/.fastdl"
readonly CONFIG_FILE="$CONFIG_DIR/config"
readonly DOWNLOADS_DIR="$HOME/Downloads/FastDL"
readonly LOG_DIR="$CONFIG_DIR/logs"
readonly TEMP_DIR="/tmp/fastdl-$"
readonly LOCK_DIR="/tmp/fastdl-locks"

# Performance settings (tunable)
DEFAULT_CONNECTIONS=32
DEFAULT_CHUNK_SIZE="1M"
DEFAULT_TIMEOUT=30
DEFAULT_RETRIES=5
DEFAULT_MAX_CONCURRENT=8
DEFAULT_BUFFER_SIZE="8M"
DEFAULT_USER_AGENT="FastDL/1.0 (Linux; High-Performance Downloader)"

# Colors for output
declare -A COLORS=(
    [RED]='\033[0;31m'
    [GREEN]='\033[0;32m'
    [YELLOW]='\033[1;33m'
    [BLUE]='\033[0;34m'
    [PURPLE]='\033[0;35m'
    [CYAN]='\033[0;36m'
    [WHITE]='\033[1;37m'
    [BOLD]='\033[1m'
    [DIM]='\033[2m'
    [NC]='\033[0m'
)

# Status indicators
declare -A STATUS=(
    [INFO]="${COLORS[BLUE]}[INFO]${COLORS[NC]}"
    [SUCCESS]="${COLORS[GREEN]}[✓]${COLORS[NC]}"
    [WARNING]="${COLORS[YELLOW]}[⚠]${COLORS[NC]}"
    [ERROR]="${COLORS[RED]}[✗]${COLORS[NC]}"
    [PROGRESS]="${COLORS[CYAN]}[→]${COLORS[NC]}"
)

# Global state
declare -A ACTIVE_DOWNLOADS=()
declare -A DOWNLOAD_PIDS=()
declare -A DOWNLOAD_STATS=()
DOWNLOAD_COUNTER=0

# Cleanup function
cleanup() {
    local exit_code=$?
    
    # Kill all background processes
    for pid in "${DOWNLOAD_PIDS[@]}"; do
        kill -TERM "$pid" 2>/dev/null || true
    done
    
    # Wait for processes to terminate
    sleep 1
    for pid in "${DOWNLOAD_PIDS[@]}"; do
        kill -KILL "$pid" 2>/dev/null || true
    done
    
    # Clean up temporary files
    [[ -d "$TEMP_DIR" ]] && rm -rf "$TEMP_DIR"
    [[ -d "$LOCK_DIR" ]] && rm -rf "$LOCK_DIR"
    
    # Restore terminal
    tput cnorm 2>/dev/null || true
    
    exit $exit_code
}

trap cleanup EXIT INT TERM

# Logging functions
log() {
    local level="$1"
    shift
    echo -e "${STATUS[$level]} $*" | tee -a "$LOG_DIR/ultrafast.log"
}

log_debug() {
    [[ "${DEBUG:-0}" == "1" ]] && echo -e "${COLORS[DIM]}[DEBUG] $*${COLORS[NC]}"
}

# System detection and optimization
detect_system() {
    local cpu_cores memory_gb disk_io_scheduler
    
    cpu_cores=$(nproc)
    memory_gb=$(($(grep MemTotal /proc/meminfo | awk '{print $2}') / 1024 / 1024))
    
    # Detect disk scheduler
    local root_device
    root_device=$(df / | tail -1 | awk '{print $1}' | sed 's/[0-9]*$//')
    root_device=${root_device##*/}
    
    if [[ -f "/sys/block/$root_device/queue/scheduler" ]]; then
        disk_io_scheduler=$(cat "/sys/block/$root_device/queue/scheduler" | grep -o '\[.*\]' | tr -d '[]')
    else
        disk_io_scheduler="unknown"
    fi
    
    log INFO "System: $cpu_cores cores, ${memory_gb}GB RAM, I/O scheduler: $disk_io_scheduler"
    
    # Auto-optimize based on system resources
    if [[ $cpu_cores -gt 16 ]]; then
        DEFAULT_CONNECTIONS=64
        DEFAULT_MAX_CONCURRENT=16
    elif [[ $cpu_cores -gt 8 ]]; then
        DEFAULT_CONNECTIONS=32
        DEFAULT_MAX_CONCURRENT=8
    elif [[ $cpu_cores -gt 4 ]]; then
        DEFAULT_CONNECTIONS=16
        DEFAULT_MAX_CONCURRENT=4
    fi
    
    # Adjust buffer size based on available memory
    if [[ $memory_gb -gt 16 ]]; then
        DEFAULT_BUFFER_SIZE="16M"
    elif [[ $memory_gb -gt 8 ]]; then
        DEFAULT_BUFFER_SIZE="8M"
    else
        DEFAULT_BUFFER_SIZE="4M"
    fi
    
    log INFO "Auto-optimized: $DEFAULT_CONNECTIONS connections, $DEFAULT_MAX_CONCURRENT concurrent, $DEFAULT_BUFFER_SIZE buffer"
}

# Check and install required tools
check_dependencies() {
    local tools=("curl" "wget" "aria2c" "axel" "pv" "parallel")
    local missing=()
    local available_tools=()
    
    for tool in "${tools[@]}"; do
        if command -v "$tool" >/dev/null 2>&1; then
            available_tools+=("$tool")
        else
            missing+=("$tool")
        fi
    done
    
    if [[ ${#available_tools[@]} -eq 0 ]]; then
        log ERROR "No download tools available! Please install curl, wget, aria2c, or axel"
        exit 1
    fi
    
    log INFO "Available tools: ${available_tools[*]}"
    
    if [[ ${#missing[@]} -gt 0 ]]; then
        log WARNING "Missing optional tools: ${missing[*]}"
        echo "To install missing tools:"
        echo "  Debian/Ubuntu: sudo apt install ${missing[*]}"
        echo "  RHEL/CentOS: sudo yum install ${missing[*]}"
        echo "  Arch: sudo pacman -S ${missing[*]}"
        echo "  Alpine: sudo apk add ${missing[*]}"
    fi
    
    # Set preferred download tool
    if command -v aria2c >/dev/null 2>&1; then
        PREFERRED_TOOL="aria2c"
    elif command -v axel >/dev/null 2>&1; then
        PREFERRED_TOOL="axel"
    elif command -v curl >/dev/null 2>&1; then
        PREFERRED_TOOL="curl"
    else
        PREFERRED_TOOL="wget"
    fi
    
    log INFO "Using $PREFERRED_TOOL as primary download engine"
}

# Display banner
show_banner() {
    echo -e "${COLORS[BOLD]}${COLORS[CYAN]}"
    cat << 'EOF'
╔══════════════════════════════════════════════════════════════════════════════╗
║                                 FastDL v1.0                                  ║
║                     High-Performance Multi-Connection Downloader             ║
║                                                                              ║
║                            Developed by 0xb0rn3 | 0xbv1                     ║
║                                                                              ║
║  Discord: oxbv1  │  X: oxbv1  │  Instagram: theehiv3  │  Email: q4n0@proton.me║
║                                                                              ║
║                      Repository: github.com/0xb0rn3/fastdl                  ║
╚══════════════════════════════════════════════════════════════════════════════╝
EOF
    echo -e "${COLORS[NC]}"
}

# Initialize configuration
init_config() {
    mkdir -p "$CONFIG_DIR" "$DOWNLOADS_DIR" "$LOG_DIR" "$TEMP_DIR" "$LOCK_DIR"
    
    if [[ ! -f "$CONFIG_FILE" ]]; then
        cat > "$CONFIG_FILE" << EOF
# FastDL Configuration
CONNECTIONS=$DEFAULT_CONNECTIONS
CHUNK_SIZE=$DEFAULT_CHUNK_SIZE
TIMEOUT=$DEFAULT_TIMEOUT
RETRIES=$DEFAULT_RETRIES
MAX_CONCURRENT=$DEFAULT_MAX_CONCURRENT
BUFFER_SIZE=$DEFAULT_BUFFER_SIZE
USER_AGENT="$DEFAULT_USER_AGENT"
DOWNLOADS_DIR="$DEFAULT_DOWNLOADS_DIR"
AUTO_RESUME=true
VERIFY_SSL=true
FOLLOW_REDIRECTS=true
PROGRESS_UPDATE_INTERVAL=0.5
EOF
        log SUCCESS "Configuration created at $CONFIG_FILE"
    fi
    
    # Load configuration
    source "$CONFIG_FILE"
}

# Detect available storage devices and directories
detect_storage() {
    local devices=()
    local mount_points=()
    
    echo -e "\n${COLORS[BOLD]}Available Storage Devices:${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    
    # Physical devices
    while IFS= read -r line; do
        local device size type mountpoint
        read -r device size type mountpoint <<< "$line"
        
        if [[ -n "$mountpoint" && "$mountpoint" != "[SWAP]" ]]; then
            local available used filesystem
            if df -h "$mountpoint" >/dev/null 2>&1; then
                read -r _ _ used available _ <<< "$(df -h "$mountpoint" | tail -1)"
                filesystem=$(findmnt -n -o FSTYPE "$mountpoint" 2>/dev/null || echo "unknown")
                
                printf "%-15s %-8s %-10s %-15s %-8s %-8s %s\n" \
                    "$device" "$size" "$type" "$mountpoint" "$filesystem" "$used" "$available"
                
                devices+=("$device:$mountpoint:$available")
            fi
        fi
    done < <(lsblk -nro NAME,SIZE,TYPE,MOUNTPOINT | grep -E "(disk|part)" | sed 's/^/\/dev\//')
    
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo "Device          Size     Type       Mount Point     FS       Used     Available"
    echo
    
    # Network mounts
    if command -v findmnt >/dev/null 2>&1; then
        echo -e "\n${COLORS[BOLD]}Network Mounts:${COLORS[NC]}"
        findmnt -t nfs,nfs4,cifs,sshfs -o TARGET,FSTYPE,SOURCE,AVAIL 2>/dev/null || echo "None detected"
    fi
    
    # Temp directories
    echo -e "\n${COLORS[BOLD]}Temporary Directories:${COLORS[NC]}"
    for tmpdir in /tmp /var/tmp; do
        if [[ -d "$tmpdir" && -w "$tmpdir" ]]; then
            local tmp_avail
            tmp_avail=$(df -h "$tmpdir" | tail -1 | awk '{print $4}')
            echo "$tmpdir (Available: $tmp_avail)"
        fi
    done
    
    return 0
}

# Get optimal download parameters for a URL
analyze_url() {
    local url="$1"
    local output_file="$TEMP_DIR/url_analysis"
    
    log INFO "Analyzing URL: $url"
    
    # Test with HEAD request to get file info
    local file_size content_type accept_ranges server last_modified
    
    if command -v curl >/dev/null 2>&1; then
        curl -sI --max-time 10 --user-agent "$USER_AGENT" "$url" > "$output_file" 2>/dev/null || {
            log ERROR "Failed to analyze URL"
            return 1
        }
    else
        wget -q --spider --timeout=10 --user-agent="$USER_AGENT" "$url" 2>/dev/null || {
            log ERROR "Failed to analyze URL"
            return 1
        }
        return 0
    fi
    
    # Parse response headers
    file_size=$(grep -i "content-length:" "$output_file" | tail -1 | awk '{print $2}' | tr -d '\r')
    content_type=$(grep -i "content-type:" "$output_file" | tail -1 | cut -d: -f2- | sed 's/^ *//' | tr -d '\r')
    accept_ranges=$(grep -i "accept-ranges:" "$output_file" | tail -1 | awk '{print $2}' | tr -d '\r')
    server=$(grep -i "server:" "$output_file" | tail -1 | cut -d: -f2- | sed 's/^ *//' | tr -d '\r')
    last_modified=$(grep -i "last-modified:" "$output_file" | tail -1 | cut -d: -f2- | sed 's/^ *//' | tr -d '\r')
    
    echo "File size: ${file_size:-unknown} bytes"
    echo "Content type: ${content_type:-unknown}"
    echo "Accept ranges: ${accept_ranges:-unknown}"
    echo "Server: ${server:-unknown}"
    echo "Last modified: ${last_modified:-unknown}"
    
    # Determine if multi-connection download is supported
    if [[ "${accept_ranges,,}" == "bytes" ]]; then
        echo "Multi-connection: Supported"
        return 0
    else
        echo "Multi-connection: Not supported"
        return 1
    fi
}

# Extract filename from URL
extract_filename() {
    local url="$1"
    local filename
    
    # Try to get filename from URL path
    filename=$(basename "$url" | sed 's/[?#].*//')
    
    # If empty or just extension, generate a name
    if [[ -z "$filename" || "$filename" == "." || "$filename" == "/" ]]; then
        filename="download_$(date +%s)"
    fi
    
    # Remove URL encoding
    filename=$(printf '%b' "${filename//%/\\x}")
    
    # Sanitize filename
    filename=$(echo "$filename" | tr -cd '[:alnum:]._-' | cut -c1-255)
    
    echo "$filename"
}

# High-performance download using aria2c
download_aria2c() {
    local url="$1"
    local output_file="$2"
    local connections="${3:-$CONNECTIONS}"
    
    local aria2_opts=(
        "--max-connection-per-server=$connections"
        "--split=$connections"
        "--min-split-size=$CHUNK_SIZE"
        "--max-download-limit=0"
        "--disable-ipv6=false"
        "--timeout=$TIMEOUT"
        "--retry-wait=1"
        "--max-tries=$RETRIES"
        "--user-agent=$USER_AGENT"
        "--follow-torrent=false"
        "--follow-metalink=false"
        "--file-allocation=falloc"
        "--disk-cache=32M"
        "--piece-length=$CHUNK_SIZE"
        "--stream-piece-selector=inorder"
        "--max-resume-failure-tries=$RETRIES"
        "--auto-file-renaming=false"
        "--allow-overwrite=true"
        "--summary-interval=1"
    )
    
    if [[ "$VERIFY_SSL" == "false" ]]; then
        aria2_opts+=("--check-certificate=false")
    fi
    
    aria2c "${aria2_opts[@]}" --dir="$(dirname "$output_file")" --out="$(basename "$output_file")" "$url"
}

# High-performance download using axel
download_axel() {
    local url="$1"
    local output_file="$2"
    local connections="${3:-$CONNECTIONS}"
    
    local axel_opts=(
        "--num-connections=$connections"
        "--timeout=$TIMEOUT"
        "--user-agent=$USER_AGENT"
        "--output=$output_file"
        "--alternate"
        "--verbose"
    )
    
    if [[ "$VERIFY_SSL" == "false" ]]; then
        axel_opts+=("--insecure")
    fi
    
    axel "${axel_opts[@]}" "$url"
}

# Fallback download using curl with parallel chunks
download_curl_parallel() {
    local url="$1"
    local output_file="$2"
    local connections="${3:-$CONNECTIONS}"
    
    # Get file size first
    local file_size
    file_size=$(curl -sI --user-agent "$USER_AGENT" "$url" | grep -i content-length | tail -1 | awk '{print $2}' | tr -d '\r')
    
    if [[ -z "$file_size" || "$file_size" -eq 0 ]]; then
        log WARNING "Cannot determine file size, falling back to single connection"
        curl --user-agent "$USER_AGENT" --location --output "$output_file" "$url"
        return
    fi
    
    local chunk_size=$((file_size / connections))
    local pids=()
    
    # Create temporary chunk files
    for ((i=0; i<connections; i++)); do
        local start=$((i * chunk_size))
        local end=$((start + chunk_size - 1))
        
        # Last chunk gets remainder
        if [[ $i -eq $((connections - 1)) ]]; then
            end=$((file_size - 1))
        fi
        
        local chunk_file="$output_file.part$i"
        
        curl --user-agent "$USER_AGENT" \
             --location \
             --range "$start-$end" \
             --output "$chunk_file" \
             --silent \
             "$url" &
        
        pids+=($!)
    done
    
    # Wait for all chunks to complete
    for pid in "${pids[@]}"; do
        wait "$pid"
    done
    
    # Combine chunks
    cat "$output_file".part* > "$output_file"
    rm -f "$output_file".part*
}

# Generic download function with automatic tool selection
download_file() {
    local url="$1"
    local output_dir="${2:-$DOWNLOADS_DIR}"
    local filename="${3:-$(extract_filename "$url")}"
    local connections="${4:-$CONNECTIONS}"
    
    local output_file="$output_dir/$filename"
    local download_id="download_$((++DOWNLOAD_COUNTER))"
    
    # Create output directory
    mkdir -p "$output_dir"
    
    # Check if file already exists
    if [[ -f "$output_file" && "$AUTO_RESUME" != "true" ]]; then
        read -p "File exists. Overwrite? [y/N]: " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            log INFO "Download cancelled"
            return 1
        fi
    fi
    
    log INFO "Starting download: $filename"
    log INFO "URL: $url"
    log INFO "Output: $output_file"
    log INFO "Connections: $connections"
    
    local start_time
    start_time=$(date +%s)
    
    # Try download tools in order of preference
    local success=false
    
    if command -v "$PREFERRED_TOOL" >/dev/null 2>&1; then
        case "$PREFERRED_TOOL" in
            aria2c)
                if download_aria2c "$url" "$output_file" "$connections"; then
                    success=true
                fi
                ;;
            axel)
                if download_axel "$url" "$output_file" "$connections"; then
                    success=true
                fi
                ;;
            curl)
                if download_curl_parallel "$url" "$output_file" "$connections"; then
                    success=true
                fi
                ;;
            wget)
                if wget --user-agent="$USER_AGENT" --output-document="$output_file" --timeout="$TIMEOUT" --tries="$RETRIES" "$url"; then
                    success=true
                fi
                ;;
        esac
    fi
    
    local end_time
    end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    if [[ "$success" == "true" && -f "$output_file" ]]; then
        local file_size
        file_size=$(stat -c%s "$output_file" 2>/dev/null || echo 0)
        local speed_mbps=0
        
        if [[ $duration -gt 0 && $file_size -gt 0 ]]; then
            speed_mbps=$(awk "BEGIN {printf \"%.2f\", $file_size / 1024 / 1024 / $duration}")
        fi
        
        log SUCCESS "Download completed: $filename"
        log INFO "Size: $(numfmt --to=iec "$file_size") | Time: ${duration}s | Speed: ${speed_mbps} MB/s"
        
        # Store download stats
        DOWNLOAD_STATS["$download_id"]="$filename:$file_size:$duration:$speed_mbps"
        
        return 0
    else
        log ERROR "Download failed: $filename"
        [[ -f "$output_file" ]] && rm -f "$output_file"
        return 1
    fi
}

# Concurrent download manager
download_batch() {
    local url_file="$1"
    local output_dir="${2:-$DOWNLOADS_DIR}"
    local max_concurrent="${3:-$MAX_CONCURRENT}"
    
    if [[ ! -f "$url_file" ]]; then
        log ERROR "URL file not found: $url_file"
        return 1
    fi
    
    local urls=()
    while IFS= read -r line; do
        line=$(echo "$line" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
        if [[ -n "$line" && ! "$line" =~ ^# ]]; then
            urls+=("$line")
        fi
    done < "$url_file"
    
    if [[ ${#urls[@]} -eq 0 ]]; then
        log ERROR "No valid URLs found in file"
        return 1
    fi
    
    log INFO "Starting batch download: ${#urls[@]} files, max $max_concurrent concurrent"
    
    local completed=0
    local failed=0
    local active_jobs=0
    local url_index=0
    
    # Start initial downloads
    while [[ $active_jobs -lt $max_concurrent && $url_index -lt ${#urls[@]} ]]; do
        local url="${urls[$url_index]}"
        local filename
        filename=$(extract_filename "$url")
        
        download_file "$url" "$output_dir" "$filename" &
        local pid=$!
        DOWNLOAD_PIDS["job_$url_index"]=$pid
        
        ((active_jobs++))
        ((url_index++))
    done
    
    # Monitor and start new downloads as others complete
    while [[ $active_jobs -gt 0 ]]; do
        for job_id in "${!DOWNLOAD_PIDS[@]}"; do
            local pid="${DOWNLOAD_PIDS[$job_id]}"
            
            if ! kill -0 "$pid" 2>/dev/null; then
                # Job completed
                if wait "$pid"; then
                    ((completed++))
                    log SUCCESS "Completed: $((completed + failed))/${#urls[@]}"
                else
                    ((failed++))
                    log ERROR "Failed: $((completed + failed))/${#urls[@]}"
                fi
                
                unset DOWNLOAD_PIDS["$job_id"]
                ((active_jobs--))
                
                # Start next download if available
                if [[ $url_index -lt ${#urls[@]} ]]; then
                    local url="${urls[$url_index]}"
                    local filename
                    filename=$(extract_filename "$url")
                    
                    download_file "$url" "$output_dir" "$filename" &
                    local new_pid=$!
                    DOWNLOAD_PIDS["job_$url_index"]=$new_pid
                    
                    ((active_jobs++))
                    ((url_index++))
                fi
            fi
        done
        
        sleep 1
    done
    
    log INFO "Batch download completed: $completed successful, $failed failed"
    return $([[ $failed -eq 0 ]])
}

# Real-time monitoring dashboard
show_dashboard() {
    while true; do
        clear
        
        echo -e "${COLORS[BOLD]}${COLORS[CYAN]}"
        echo "╔══════════════════════════════════════════════════════════════════════════════╗"
        echo "║                                 FastDL v1.0                                  ║"
        echo "║                              Real-time Dashboard                            ║"
        echo "╚══════════════════════════════════════════════════════════════════════════════╝"
        echo -e "${COLORS[NC]}"
        
        # System stats
        echo -e "\n${COLORS[BOLD]}System Status:${COLORS[NC]}"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        
        local load_avg memory_usage disk_usage network_usage
        load_avg=$(uptime | awk -F'load average:' '{print $2}' | sed 's/^[[:space:]]*//')
        memory_usage=$(free | awk 'NR==2{printf "%.1f%%", $3*100/$2}')
        disk_usage=$(df "$DOWNLOADS_DIR" | tail -1 | awk '{print $5}')
        
        # Network usage (if available)
        if command -v vnstat >/dev/null 2>&1; then
            network_usage=$(vnstat -i eth0 --json | jq -r '.interfaces[0].traffic.day[0].tx' 2>/dev/null || echo "N/A")
        else
            network_usage="N/A"
        fi
        
        printf "Load: %-20s Memory: %-10s Disk: %-10s Network: %s\n" \
            "$load_avg" "$memory_usage" "$disk_usage" "$network_usage"
        
        # Active downloads
        echo -e "\n${COLORS[BOLD]}Active Downloads:${COLORS[NC]}"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        
        if [[ ${#DOWNLOAD_PIDS[@]} -eq 0 ]]; then
            echo "No active downloads"
        else
            printf "%-20s %-10s %-15s %s\n" "PID" "Status" "Progress" "File"
            for job_id in "${!DOWNLOAD_PIDS[@]}"; do
                local pid="${DOWNLOAD_PIDS[$job_id]}"
                if kill -0 "$pid" 2>/dev/null; then
                    printf "%-20s %-10s %-15s %s\n" "$pid" "Running" "..." "${job_id#job_}"
                fi
            done
        fi
        
        # Recent completions
        if [[ ${#DOWNLOAD_STATS[@]} -gt 0 ]]; then
            echo -e "\n${COLORS[BOLD]}Recent Completions:${COLORS[NC]}"
            echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
            printf "%-30s %-12s %-8s %s\n" "File" "Size" "Time" "Speed"
            
            local count=0
            for download_id in "${!DOWNLOAD_STATS[@]}"; do
                if [[ $count -ge 5 ]]; then break; fi
                
                IFS=':' read -r filename size duration speed <<< "${DOWNLOAD_STATS[$download_id]}"
                local size_human
                size_human=$(numfmt --to=iec "$size")
                printf "%-30s %-12s %-8s %s MB/s\n" \
                    "${filename:0:29}" "$size_human" "${duration}s" "$speed"
                ((count++))
            done
        fi
        
        echo -e "\n${COLORS[DIM]}Press Ctrl+C to exit dashboard${COLORS[NC]}"
        sleep 2
    done
}

# Interactive menu system
show_main_menu() {
    clear
    show_banner
    
    echo -e "\n${COLORS[BOLD]}Main Menu:${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    echo "  1) Single File Download"
    echo "  2) Batch Download (from file)"
    echo "  3) Torrent Download"
    echo "  4) System Analysis"
    echo "  5) Storage Detection"
    echo "  6) Real-time Dashboard"
    echo "  7) Configuration"
    echo "  8) Performance Test"
    echo "  9) Help & About"
    echo "  0) Exit"
    echo
    echo -n "Select option [0-9]: "
}

# Single download interface
single_download_interface() {
    clear
    echo -e "${COLORS[BOLD]}Single File Download${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    read -p "Enter URL: " url
    if [[ -z "$url" ]]; then
        log ERROR "URL cannot be empty"
        read -p "Press Enter to continue..." -r
        return
    fi
    
    echo
    echo "Analyzing URL..."
    if analyze_url "$url"; then
        local supports_multiconnection=true
    else
        local supports_multiconnection=false
    fi
    
    echo
    local filename
    filename=$(extract_filename "$url")
    read -p "Output filename [$filename]: " custom_filename
    filename="${custom_filename:-$filename}"
    
    read -p "Output directory [$DOWNLOADS_DIR]: " output_dir
    output_dir="${output_dir:-$DOWNLOADS_DIR}"
    
    if [[ "$supports_multiconnection" == "true" ]]; then
        read -p "Number of connections [$CONNECTIONS]: " connections
        connections="${connections:-$CONNECTIONS}"
    else
        connections=1
        echo "Note: Server doesn't support multi-connection downloads"
    fi
    
    echo
    log INFO "Starting download..."
    if download_file "$url" "$output_dir" "$filename" "$connections"; then
        echo
        read -p "Download completed! Press Enter to continue..." -r
    else
        echo
        read -p "Download failed! Press Enter to continue..." -r
    fi
}

# Batch download interface
batch_download_interface() {
    clear
    echo -e "${COLORS[BOLD]}Batch Download${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    read -p "Enter path to URL file: " url_file
    if [[ ! -f "$url_file" ]]; then
        log ERROR "File not found: $url_file"
        read -p "Press Enter to continue..." -r
        return
    fi
    
    local url_count
    url_count=$(grep -c -v '^\s*$\|^\s*#' "$url_file" 2>/dev/null || echo "0")
    echo "Found $url_count URLs in file"
    
    read -p "Output directory [$DOWNLOADS_DIR]: " output_dir
    output_dir="${output_dir:-$DOWNLOADS_DIR}"
    
    read -p "Max concurrent downloads [$MAX_CONCURRENT]: " max_concurrent
    max_concurrent="${max_concurrent:-$MAX_CONCURRENT}"
    
    echo
    log INFO "Starting batch download..."
    if download_batch "$url_file" "$output_dir" "$max_concurrent"; then
        echo
        read -p "Batch download completed! Press Enter to continue..." -r
    else
        echo
        read -p "Batch download finished with errors! Press Enter to continue..." -r
    fi
}

# Torrent download interface
torrent_download_interface() {
    clear
    echo -e "${COLORS[BOLD]}Torrent Download${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    if ! command -v aria2c >/dev/null 2>&1; then
        log ERROR "aria2c is required for torrent downloads"
        echo "Install with: sudo apt install aria2"
        read -p "Press Enter to continue..." -r
        return
    fi
    
    read -p "Enter torrent file path or magnet link: " torrent_input
    if [[ -z "$torrent_input" ]]; then
        log ERROR "Input cannot be empty"
        read -p "Press Enter to continue..." -r
        return
    fi
    
    read -p "Download directory [$DOWNLOADS_DIR]: " download_dir
    download_dir="${download_dir:-$DOWNLOADS_DIR}"
    
    read -p "Max upload speed (0=unlimited) [0]: " max_upload
    max_upload="${max_upload:-0}"
    
    read -p "Max connections per torrent [50]: " max_connections
    max_connections="${max_connections:-50}"
    
    echo
    log INFO "Starting torrent download..."
    
    local aria2_torrent_opts=(
        "--dir=$download_dir"
        "--max-upload-limit=${max_upload}K"
        "--max-connection-per-server=$max_connections"
        "--seed-time=0"
        "--follow-torrent=true"
        "--enable-dht=true"
        "--enable-peer-exchange=true"
        "--bt-enable-lpd=true"
        "--bt-max-peers=100"
        "--summary-interval=5"
        "--console-log-level=info"
    )
    
    if aria2c "${aria2_torrent_opts[@]}" "$torrent_input"; then
        log SUCCESS "Torrent download completed!"
    else
        log ERROR "Torrent download failed!"
    fi
    
    echo
    read -p "Press Enter to continue..." -r
}

# System analysis
system_analysis() {
    clear
    echo -e "${COLORS[BOLD]}System Analysis${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    # CPU Information
    echo -e "${COLORS[BOLD]}CPU Information:${COLORS[NC]}"
    echo "Model: $(grep 'model name' /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[[:space:]]*//')"
    echo "Cores: $(nproc) physical, $(nproc --all) logical"
    echo "Architecture: $(uname -m)"
    echo "Current frequency: $(cat /proc/cpuinfo | grep 'cpu MHz' | head -1 | cut -d: -f2 | sed 's/^[[:space:]]*//')MHz"
    
    if [[ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor ]]; then
        echo "CPU governor: $(cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor)"
    fi
    
    echo
    
    # Memory Information
    echo -e "${COLORS[BOLD]}Memory Information:${COLORS[NC]}"
    local mem_info
    mem_info=$(free -h | grep '^Mem:')
    echo "Total: $(echo "$mem_info" | awk '{print $2}')"
    echo "Used: $(echo "$mem_info" | awk '{print $3}')"
    echo "Available: $(echo "$mem_info" | awk '{print $7}')"
    echo "Swap: $(free -h | grep '^Swap:' | awk '{print $2}')"
    
    echo
    
    # Network Information
    echo -e "${COLORS[BOLD]}Network Interfaces:${COLORS[NC]}"
    for interface in $(ls /sys/class/net/ | grep -v lo); do
        local speed link_status
        if [[ -f "/sys/class/net/$interface/speed" ]]; then
            speed=$(cat "/sys/class/net/$interface/speed" 2>/dev/null || echo "unknown")
            if [[ "$speed" != "unknown" && "$speed" -gt 0 ]]; then
                speed="${speed}Mbps"
            fi
        else
            speed="unknown"
        fi
        
        if [[ -f "/sys/class/net/$interface/carrier" ]]; then
            link_status=$(cat "/sys/class/net/$interface/carrier" 2>/dev/null || echo "0")
            link_status=$([[ "$link_status" == "1" ]] && echo "up" || echo "down")
        else
            link_status="unknown"
        fi
        
        echo "$interface: Speed=$speed, Status=$link_status"
    done
    
    echo
    
    # Disk Information
    echo -e "${COLORS[BOLD]}Storage Performance:${COLORS[NC]}"
    local temp_file="$TEMP_DIR/disk_test"
    
    echo "Testing disk write speed..."
    local write_speed
    write_speed=$(dd if=/dev/zero of="$temp_file" bs=1M count=100 2>&1 | grep -o '[0-9.]\+ MB/s' | tail -1 || echo "unknown")
    echo "Write speed: $write_speed"
    
    echo "Testing disk read speed..."
    local read_speed
    read_speed=$(dd if="$temp_file" of=/dev/null bs=1M 2>&1 | grep -o '[0-9.]\+ MB/s' | tail -1 || echo "unknown")
    echo "Read speed: $read_speed"
    
    rm -f "$temp_file"
    
    echo
    
    # Network speed test (if possible)
    echo -e "${COLORS[BOLD]}Network Speed Test:${COLORS[NC]}"
    if command -v curl >/dev/null 2>&1; then
        echo "Testing download speed with a small file..."
        local test_url="http://speedtest.ftp.otenet.gr/files/test100k.db"
        local net_speed
        net_speed=$(curl -w '%{speed_download}' -o /dev/null -s "$test_url" 2>/dev/null | awk '{printf "%.2f KB/s", $1/1024}')
        echo "Download speed: $net_speed"
    else
        echo "curl not available for network test"
    fi
    
    echo
    read -p "Press Enter to continue..." -r
}

# Configuration interface
configuration_interface() {
    clear
    echo -e "${COLORS[BOLD]}Configuration${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    echo "Current configuration:"
    echo "1) Connections per download: $CONNECTIONS"
    echo "2) Chunk size: $CHUNK_SIZE"
    echo "3) Timeout: $TIMEOUT seconds"
    echo "4) Retries: $RETRIES"
    echo "5) Max concurrent downloads: $MAX_CONCURRENT"
    echo "6) Buffer size: $BUFFER_SIZE"
    echo "7) Downloads directory: $DOWNLOADS_DIR"
    echo "8) Auto resume: $AUTO_RESUME"
    echo "9) Verify SSL: $VERIFY_SSL"
    echo
    echo "0) Save and exit"
    echo "r) Reset to defaults"
    echo
    read -p "Select option to modify [0-9,r]: " config_choice
    
    case "$config_choice" in
        1)
            read -p "Enter new connections per download [$CONNECTIONS]: " new_connections
            if [[ -n "$new_connections" && "$new_connections" =~ ^[0-9]+$ ]]; then
                CONNECTIONS="$new_connections"
            fi
            ;;
        2)
            read -p "Enter new chunk size [$CHUNK_SIZE]: " new_chunk_size
            if [[ -n "$new_chunk_size" ]]; then
                CHUNK_SIZE="$new_chunk_size"
            fi
            ;;
        3)
            read -p "Enter new timeout in seconds [$TIMEOUT]: " new_timeout
            if [[ -n "$new_timeout" && "$new_timeout" =~ ^[0-9]+$ ]]; then
                TIMEOUT="$new_timeout"
            fi
            ;;
        4)
            read -p "Enter new retry count [$RETRIES]: " new_retries
            if [[ -n "$new_retries" && "$new_retries" =~ ^[0-9]+$ ]]; then
                RETRIES="$new_retries"
            fi
            ;;
        5)
            read -p "Enter max concurrent downloads [$MAX_CONCURRENT]: " new_max_concurrent
            if [[ -n "$new_max_concurrent" && "$new_max_concurrent" =~ ^[0-9]+$ ]]; then
                MAX_CONCURRENT="$new_max_concurrent"
            fi
            ;;
        6)
            read -p "Enter new buffer size [$BUFFER_SIZE]: " new_buffer_size
            if [[ -n "$new_buffer_size" ]]; then
                BUFFER_SIZE="$new_buffer_size"
            fi
            ;;
        7)
            read -p "Enter new downloads directory [$DOWNLOADS_DIR]: " new_downloads_dir
            if [[ -n "$new_downloads_dir" ]]; then
                DOWNLOADS_DIR="$new_downloads_dir"
                mkdir -p "$DOWNLOADS_DIR"
            fi
            ;;
        8)
            read -p "Auto resume downloads? [true/false] [$AUTO_RESUME]: " new_auto_resume
            if [[ "$new_auto_resume" =~ ^(true|false)$ ]]; then
                AUTO_RESUME="$new_auto_resume"
            fi
            ;;
        9)
            read -p "Verify SSL certificates? [true/false] [$VERIFY_SSL]: " new_verify_ssl
            if [[ "$new_verify_ssl" =~ ^(true|false)$ ]]; then
                VERIFY_SSL="$new_verify_ssl"
            fi
            ;;
        0)
            # Save configuration
            cat > "$CONFIG_FILE" << EOF
# UltraFast Downloader Configuration
CONNECTIONS=$CONNECTIONS
CHUNK_SIZE=$CHUNK_SIZE
TIMEOUT=$TIMEOUT
RETRIES=$RETRIES
MAX_CONCURRENT=$MAX_CONCURRENT
BUFFER_SIZE=$BUFFER_SIZE
USER_AGENT="$USER_AGENT"
DOWNLOADS_DIR="$DOWNLOADS_DIR"
AUTO_RESUME=$AUTO_RESUME
VERIFY_SSL=$VERIFY_SSL
FOLLOW_REDIRECTS=$FOLLOW_REDIRECTS
PROGRESS_UPDATE_INTERVAL=$PROGRESS_UPDATE_INTERVAL
EOF
            log SUCCESS "Configuration saved!"
            return
            ;;
        r)
            CONNECTIONS=$DEFAULT_CONNECTIONS
            CHUNK_SIZE=$DEFAULT_CHUNK_SIZE
            TIMEOUT=$DEFAULT_TIMEOUT
            RETRIES=$DEFAULT_RETRIES
            MAX_CONCURRENT=$DEFAULT_MAX_CONCURRENT
            BUFFER_SIZE=$DEFAULT_BUFFER_SIZE
            DOWNLOADS_DIR="$HOME/Downloads/FastDL"
            AUTO_RESUME=true
            VERIFY_SSL=true
            log SUCCESS "Configuration reset to defaults!"
            ;;
    esac
    
    configuration_interface
}

# Performance test
performance_test() {
    clear
    echo -e "${COLORS[BOLD]}Performance Test${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    echo "This will test download performance with different connection counts."
    echo "Test files will be downloaded to verify optimal settings for your system."
    echo
    read -p "Continue with performance test? [y/N]: " -n 1 -r
    echo
    
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        return
    fi
    
    local test_url="http://speedtest.ftp.otenet.gr/files/test10Mb.db"
    local test_connections=(1 4 8 16 32)
    local results=()
    
    echo
    log INFO "Starting performance test..."
    
    for conn in "${test_connections[@]}"; do
        log INFO "Testing with $conn connections..."
        
        local start_time end_time duration speed
        start_time=$(date +%s.%N)
        
        if download_file "$test_url" "$TEMP_DIR" "test_${conn}conn.tmp" "$conn" >/dev/null 2>&1; then
            end_time=$(date +%s.%N)
            duration=$(awk "BEGIN {printf \"%.2f\", $end_time - $start_time}")
            
            local file_size
            file_size=$(stat -c%s "$TEMP_DIR/test_${conn}conn.tmp" 2>/dev/null || echo 0)
            speed=$(awk "BEGIN {printf \"%.2f\", $file_size / 1024 / 1024 / $duration}")
            
            results+=("$conn:$duration:$speed")
            rm -f "$TEMP_DIR/test_${conn}conn.tmp"
            
            echo "  $conn connections: ${duration}s, ${speed} MB/s"
        else
            echo "  $conn connections: FAILED"
        fi
    done
    
    echo
    echo -e "${COLORS[BOLD]}Performance Test Results:${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    printf "%-15s %-15s %s\n" "Connections" "Time (s)" "Speed (MB/s)"
    
    local best_speed=0
    local best_connections=1
    
    for result in "${results[@]}"; do
        IFS=':' read -r conn duration speed <<< "$result"
        printf "%-15s %-15s %s\n" "$conn" "$duration" "$speed"
        
        if awk "BEGIN {exit !($speed > $best_speed)}"; then
            best_speed="$speed"
            best_connections="$conn"
        fi
    done
    
    echo
    log SUCCESS "Optimal setting: $best_connections connections (${best_speed} MB/s)"
    echo
    read -p "Apply optimal settings? [y/N]: " -n 1 -r
    echo
    
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        CONNECTIONS="$best_connections"
        log SUCCESS "Settings updated!"
    fi
    
    echo
    read -p "Press Enter to continue..." -r
}

# Help and about
help_interface() {
    clear
    echo -e "${COLORS[BOLD]}Help & About${COLORS[NC]}"
    echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
    echo
    
    echo -e "${COLORS[BOLD]}FastDL v$SCRIPT_VERSION${COLORS[NC]}"
    echo "Extreme performance file downloader for Linux"
    echo "Author: $SCRIPT_AUTHOR"
    echo "Contact: $SCRIPT_CONTACT"
    echo "Repository: $SCRIPT_REPO"
    echo
    echo -e "${COLORS[BOLD]}Features:${COLORS[NC]}"
    echo "• Multi-connection downloads for maximum speed"
    echo "• Concurrent batch downloading"
    echo "• Torrent support via aria2c"
    echo "• Real-time system monitoring"
    echo "• Automatic performance optimization"
    echo "• Resume interrupted downloads"
    echo "• Cross-distro Linux compatibility"
    echo
    echo -e "${COLORS[BOLD]}Supported Tools:${COLORS[NC]}"
    echo "• aria2c (recommended) - Advanced download utility"
    echo "• axel - Multi-connection downloader"
    echo "• curl - HTTP/HTTPS client with range support"
    echo "• wget - Traditional web retriever"
    echo
    echo -e "${COLORS[BOLD]}Installation Requirements:${COLORS[NC]}"
    echo "• bash 4.0+"
    echo "• coreutils (standard Linux utilities)"
    echo "• One or more download tools (aria2c, axel, curl, wget)"
    echo "• Optional: pv, parallel for enhanced features"
    echo
    echo -e "${COLORS[BOLD]}Command Line Usage:${COLORS[NC]}"
    echo "  $0                          - Interactive mode"
    echo "  $0 --download <url>         - Quick download"
    echo "  $0 --batch <file>           - Batch download"
    echo "  $0 --analyze <url>          - Analyze URL"
    echo "  $0 --dashboard              - Real-time dashboard"
    echo "  $0 --config                 - Configuration"
    echo "  $0 --help                   - This help"
    echo
    echo -e "${COLORS[BOLD]}Configuration Files:${COLORS[NC]}"
    echo "• Config: $CONFIG_FILE"
    echo "• Logs: $LOG_DIR/"
    echo "• Downloads: $DOWNLOADS_DIR"
    echo
    read -p "Press Enter to continue..." -r
}

# Command line argument handling
handle_cli_args() {
    case "${1:-}" in
        --download|-d)
            [[ -z "${2:-}" ]] && { log ERROR "URL required"; exit 1; }
            init_config
            check_dependencies
            download_file "$2"
            ;;
        --batch|-b)
            [[ -z "${2:-}" ]] && { log ERROR "File path required"; exit 1; }
            init_config
            check_dependencies
            download_batch "$2"
            ;;
        --analyze|-a)
            [[ -z "${2:-}" ]] && { log ERROR "URL required"; exit 1; }
            init_config
            check_dependencies
            analyze_url "$2"
            ;;
        --dashboard)
            init_config
            check_dependencies
            show_dashboard
            ;;
        --config)
            init_config
            configuration_interface
            ;;
        --storage)
            detect_storage
            ;;
        --help|-h)
            help_interface
            ;;
        --version|-v)
            echo "$SCRIPT_NAME v$SCRIPT_VERSION"
            ;;
        "")
            # No arguments - run interactive mode
            ;;
        *)
            echo "Usage: $0 [option] [arguments]"
            echo "Try '$0 --help' for more information."
            exit 1
            ;;
    esac
}

# Main interactive loop
main_loop() {
    while true; do
        show_main_menu
        read -r choice
        
        case "$choice" in
            1) single_download_interface ;;
            2) batch_download_interface ;;
            3) torrent_download_interface ;;
            4) system_analysis ;;
            5) detect_storage; read -p "Press Enter to continue..." -r ;;
            6) show_dashboard ;;
            7) configuration_interface ;;
            8) performance_test ;;
            9) help_interface ;;
            0) 
                echo
                log INFO "Thanks for using FastDL!"
                exit 0
                ;;
            *)
                log ERROR "Invalid choice. Please select 0-9."
                sleep 1
                ;;
        esac
    done
}

# Main execution
main() {
    # Handle command line arguments
    if [[ $# -gt 0 ]]; then
        handle_cli_args "$@"
        exit 0
    fi
    
    # Initialize
    init_config
    detect_system
    check_dependencies
    
    # Start interactive mode
    main_loop
}

# Execute main function with all arguments
main "$@"
